@article{Hansen198389,
title = "An interval Newton method ",
journal = "Applied Mathematics and Computation ",
volume = "12",
number = "2–3",
pages = "89 - 98",
year = "1983",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(83)90001-2",
url = "http://www.sciencedirect.com/science/article/pii/0096300383900012",
author = "E.R. Hansen and R.I. Greenberg",
abstract = "We introduce an interval Newton method for bounding solutions of systems of nonlinear equations. It entails three subalgorithms. The first is a Gauss-Seidel-type step. The second is a real (noninterval) Newton iteration. The third solves the linearized equations by elimination. We explain why each subalgorithm is desirable and how they fit together to provide solutions in as little as one-third or one-quarter the time required by Krawczyk's method [7] in our implementations. "
}
@article{Dinkel1988211,
title = "Interval Newton methods and perturbed problems ",
journal = "Applied Mathematics and Computation ",
volume = "28",
number = "3",
pages = "211 - 222",
year = "1988",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(88)90137-3",
url = "http://www.sciencedirect.com/science/article/pii/0096300388901373",
author = "John J. Dinkel and Marietta Tretter and Danny Wong",
abstract = "This paper describes a straightforward implementation of a modified Newton algorithm which generates the best interval bounding the solution generated using interval Newton methods. This implementation addresses the issues described by Hansen and Greenberg for analyzing problems with data perturbations using interval analysis. It also indicates a new approach of potentially attractive methods for using interval Newton methods. While our focus is on perturbed problems (sensitivity analysis), the results are more generally applicable. The major difference in the point of view of perturbed problems versus the general use of interval methods is that in perturbed problems we are focused on the behavior of the function around an optimal solution. The more general approach seeks to identify all optimal solutions of the function. "
}
@article{Zuhe1992403,
title = "Slope tests for newton-type methods ",
journal = "Applied Mathematics and Computation ",
volume = "52",
number = "2–3",
pages = "403 - 416",
year = "1992",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(92)90090-N",
url = "http://www.sciencedirect.com/science/article/pii/009630039290090N",
author = "Shen Zuhe and M.A. Wolfe",
abstract = "It is shown that the computable test for the existence of a solution of a system of nonlinear algebraic equations in a given region due to Pandian [8] may be weakened, and that sharp componentwise error bounds can be obtained if derivatives are replaced with slopes [4], [12]. Illustrative numerical examples are presented. "
}
@article{Muraskin1992417,
title = "Beyond Newton and Leibniz ",
journal = "Applied Mathematics and Computation ",
volume = "52",
number = "2–3",
pages = "417 - 438",
year = "1992",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(92)90091-E",
url = "http://www.sciencedirect.com/science/article/pii/009630039290091E",
author = "M. Muraskin",
abstract = "We point out the restrictive character of the calculus. With the use of high speed computers, generalizations of the calculus can be studied. Such generalizations are natural and open up a realm of new possibilities. As an example, we study a soliton system in three space-time dimensions. "
}
@article{Childs1976273,
title = "An efficient Newton's method for optimization under equality constraints ",
journal = "Applied Mathematics and Computation ",
volume = "2",
number = "3",
pages = "273 - 282",
year = "1976",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(76)90005-9",
url = "http://www.sciencedirect.com/science/article/pii/0096300376900059",
author = "Bart Childs and M.J. Maron",
abstract = "An efficient procedure for optimizing a nonlinear objective functional ⨍(x) under linear and/or nonlinear equality constraints is given. The linearly constrained, quadratic ⨍(x) case is shown to have a solution given by the explicit formula x = xp - N(N′AN)-1N′(Axp + b/2), where ⨍(x) = a+b′x+x′Ax(xϵRn) is convex, and both xpϵRn and N [an n×(n-r) matrix]; can be obtained simultaneously from the constraint set, Kx=c (K of rank r&lt;n), by a single Gaussian elimination. The nonlinearly constrained, arbitrary ⨍(x) case is treated by an interative scheme in which the above formula is used to “project” onto approximate solutions satisfying linear approximations of the constraints. This method does not require the initial guess or the iterated values to be in the feasible region. The resulting algorithm does appear to be efficient. "
}
@article{Argyros199425,
title = "A convergence theorem for Newton-like methods under generalized Chen-Yamamoto-type assumptions ",
journal = "Applied Mathematics and Computation ",
volume = "61",
number = "1",
pages = "25 - 37",
year = "1994",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(94)90144-9",
url = "http://www.sciencedirect.com/science/article/pii/0096300394901449",
author = "Ioannis K. Argyros",
abstract = "In this study, we provide sufficient conditions for the convergence of a Newton-like method to a locally unique solution of a nonlinear equation with a nondifferentiable term in a Banach space setting. We introduce new conditions by assuming the existence of real functions of two variables that serve as upper bounds on the operators involved. Special choices of the real functions mentioned above lead to Chen-Yamamoto-type assumptions or the usual Lipschitz conditions associated with the Fréchet derivatives of the nonlinear operators involved. Using the majorant method, we show that if a certain scalar inequality has a minimum positive solution, then the abstract equation has a locally unique solution also. We also show that our upper bounds on the distances ‖xn+1 – xn‖ and ‖xn – x∗‖ improve on earlier ones found by Chen-Yamamoto, Dennis, Rheinboldt, and Potra et al. Finally, our results can apply to solve nonlinear integral equations of Uryson type. "
}
@article{Zuhe19901,
title = "A ball Newton point algorithm for bounding zeros of analytic functions ",
journal = "Applied Mathematics and Computation ",
volume = "36",
number = "1",
pages = "1 - 14",
year = "1990",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(90)90071-A",
url = "http://www.sciencedirect.com/science/article/pii/009630039090071A",
author = "Shen Zuhe and M.A. Wolfe",
abstract = "A ball Newton algorithm for bounding simple zeros of analytic functions is presented. It is shown that Nickel's simplified ball Newton algorithm \{SNA\} can be combined with locally convergent point iterative procedures to obtain rapid convergence. Some numerical results are presented. "
}
@article{Madan1990263,
title = "Interval Newton method: Hansen-Greenberg approach—some procedural improvements ",
journal = "Applied Mathematics and Computation ",
volume = "35",
number = "3",
pages = "263 - 276",
year = "1990",
note = "",
issn = "0096-3003",
doi = "http://dx.doi.org/10.1016/0096-3003(90)90046-6",
url = "http://www.sciencedirect.com/science/article/pii/0096300390900466",
author = "Ved P. Madan",
abstract = "E.R. Hansen and R.I. Greenberg have presented an interval Newton method to solve a system of n nonlinear equations in n real variables. Following R.E. Moore, they have linearized the system using a mean value expansion, and used preconditioning technique due to Hansen and R.R. Smith to modify the system. The modified system is subjected to a Hansen-Sengupta step to obtain an updated interval containing the solution. Hansen and Greenberg have in fact used the subalgorithms of preconditioning and Hansen-Sengupta step witha real (local, noninterval) iteration and an elimination procedure to provide an algorithm of greater efficiency. In this paper, we indicate procedures which will further improve the efficiency of the Hansen-Greenberg algorithm. Firstly, a better approximating matrix for the identity is obtained. Secondly, a successive overrelaxation (SOR) technique is introduced to replace the Hansen-Sengupta step if necessary. Finally, an interval iteration is suggested to provide an alternative to the real (noninterval) inner iteration introduced by Hansen and Greenberg. Examples are included to show improvement in results and/or the forms the new procedures would take. the additional procedures provide more efficient results besides improving the techniques. "
}

